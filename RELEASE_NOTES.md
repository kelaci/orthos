# üöÄ ORTHOS v5.0.0 Release Notes - The Rebranding Release

We are excited to announce **ORTHOS v5.0.0**, a major identity transformation that aligns the codebase with its mathematical foundations: **Orthogonal Recursive Hierarchical Optimization System**.

## üåü Key Highlights

### 1. üè∑Ô∏è Full Rebranding
- **Name Change**: Transitioned from ORTHOS to **ORTHOS** across the entire codebase, documentation, and metadata.
- **Identity**: Refocused the project's vision on **orthogonality**, **recursive optimization**, and **probabilistic filtering**.
- **Package Relocation**: Main package directory renamed from `orthos/` to `orthos/`.

### 2. üì¶ Infrastructure Updates
- **PyPI Readiness**: Updated `pyproject.toml` and `setup.py` with new package names (`orthos-framework`, `orthos-neuro`).
- **Version Bump**: Bumped from 4.2.0 to **5.0.0** to reflect the major non-functional changes and breaking import changes.
- **Migration Path**: Introduced `MIGRATION_ORTHOS_TO_ORTHOS.md` to assist current users.

### 3. üß™ Validation
- **Unified Test Suite**: `test_orthos.py` has been evolved into `test_orthos.py`.
- **Verified Stability**: Maintained 100% pass rate on all core and integration tests through the rebranding process.

### 4. üìñ Documentation Overhaul
- **Terminology**: updated all references from "Generalized Adaptive Intelligent Architecture" to "Orthogonal Recursive Hierarchical Optimization System".
- **Mathematical Deep Dive**: Renamed and updated the deep dive document to `ORTHOS_MATHEMATICAL_METHODS_DEEP_DIVE_EN.md`.

## ‚ö†Ô∏è Breaking Changes

- **Import Namespaces**: All code previously importing from `orthos` must now import from `orthos`.
- **File Names**: Several core scripts have been renamed (e.g., `run_orthos_v42.py` ‚Üí `run_orthos_v42.py`).

## üõ†Ô∏è Full Changelog

- **Renamed**: `orthos/` directory to `orthos/`.
- **Renamed**: `test_orthos.py` to `test_orthos.py`.
- **Renamed**: `run_orthos_v42.py` to `run_orthos_v42.py`.
- **Renamed**: `ORTHOS_MATHEMATICAL_METHODS_DEEP_DIVE_EN.md` to `ORTHOS_MATHEMATICAL_METHODS_DEEP_DIVE_EN.md`.
- **Updated**: `pyproject.toml`, `setup.py`, and `requirements.txt`.
- **Updated**: All docstrings, comments, and strings in Python files.
- **Updated**: All Markdown headers and project descriptions.

## üîú Next Steps: v5.1
Focus shifts to **Structural Plasticity** (Sparse Attention) and advanced attention mechanisms within the ORTHOS hierarchy.

---

# üöÄ ORTHOS v4.2.0 Release Notes

We are proud to announce **ORTHOS v4.2.0**, featuring the **Probabilistic Spine**‚Äîa major advancement in hierarchical consistency and numerical stability. See [Detailed Consolidation Improvements](docs/architecture/consolidation_improvements_v42.md) for a full technical breakdown.

## üåü Key Highlights

### 1. üìä Probabilistic Spine
- **Sequential Bayesian Estimation**: Integrated Kalman, EKF, and Particle Filters at hierarchical levels.
- **Hierarchical Consensus**: "Wisdom of Crowds" aggregation to resolve state estimation across levels.
- **Top-Down Feedback**: Bidirectional information flow where global consensus informs local predictions.

### 2. ‚ö° Performance Optimizations
- **Diagonal Covariance Approximation**: 12x speedup and 128x memory reduction for high-dimensional state spaces (>64 dims).
- **Auto-Projection**: Seamless handling of mismatched dimensions between levels (upsampling/downsampling).
- **Joseph Form Stability**: Guaranteed positive semi-definiteness for long-running systems.

### 3. üöÅ Drone Saviour Protocol (Research Utility)
- **Chaos Resilience**: Validated stability under extreme sensor noise and drop-outs.
- **Emergency Handover**: Real-time switch from GPS to optical flow/IMU fusion via the Probabilistic Spine.

### 4. üìê Mathematical Deep Dive
- Released the [Comprehensive Mathematical Methods Deep Dive](ORTHOS_MATHEMATICAL_METHODS_DEEP_DIVE_EN.md), detailing the Bayesian foundations of ORTHOS.

## üõ†Ô∏è Full Changelog

- **Added**: `orthos/filters/` directory with `KalmanFilter`, `ExtendedKalmanFilter`, and `ParticleFilter`.
- **Added**: `orthos/consensus/` directory with `ConsensusEngine` for multi-level aggregation.
- **Added**: `ConsensusHierarchyManager` with `auto_projection` and `top_down_feedback`.
- **Improved**: `KalmanFilter` now supports `use_diagonal_covariance`, `use_joseph_form`, and `min_obs_noise`.
- **Improved**: `ARCHITECTURE.md` and `README.md` updated to reflect the Probabilistic Spine.
- **Fixed**: `AttributeError` in consensus managers for `aggregated_prediction`.
- **Fixed**: Innovation scaling bug in adaptive noise estimation.

## üîú Next Steps: v4.3
Focus shifts to **Structural Plasticity** (Sparse Attention) and **CMA-ES** for robust meta-optimization.

---

# üöÄ ORTHOS v4.1.0 Release Notes

We are thrilled to announce the open-source release of **ORTHOS v4.1.0** (Orthogonal Recursive Hierarchical Optimization System). This release marks a significant milestone in providing a robust, research-grade framework for biologically-inspired AI.

## üåü Key Highlights

### 1. üì¶ Installation Experience (Score: 10/10)
- **Standard Packaging**: Added `pyproject.toml`, `MANIFEST.in`, and `setup.py`.
- **Easy Install**: Now installable via `pip install .` or `pip install -e .` for development.
- **Dependencies**: Streamlined requirements managed via standard metadata.

### 2. ‚ú® Feature Completeness (v4.1 Final)
- **STDP Implementation**: Added a rate-based approximation for Spike-Timing Dependent Plasticity (STDP) in `STDPRule`, enabling temporal learning dynamics in a rate-coded framework.
- **Meta-Learning Improvements**:
    - **Hill Climbing**: Replaced heuristic meta-updates with a robust Hill Climbing strategy for outer-loop optimization.
    - **Early Stopping**: Added convergence checks to the inner loop for efficiency.
    - **Task Sampling Strategies**: Implemented `uniform`, `curriculum`, and `performance_weighted` strategies.
- **Hierarchy Management**: Solidified strict hierarchical relationships and cleaned up level removal logic.
- **Configuration System**: 
    - Full type validation against default schemas.
    - Recursive dictionary merging for nested configs.
    - Configuration templates with descriptions for all parameters.

### 3. ‚ö° Performance & Benchmarking
- **New Benchmark Suite**: Included `benchmark.py` to evaluate hierarchical scaling.
- **Performance**: Achieves >13,000 steps/sec on a 10-level deep hierarchy (single threaded).

### 4. üöÄ GPU Acceleration (Hybrid)
- **Dynamic Dispatch**: Implemented `gpu_utils` and refactored core tensors/layers (`ReactiveLayer`, `HebbianCore`) to automatically switch between **NumPy** (CPU) and **CuPy** (GPU) based on availability.
- **Seamless Fallback**: Systems without GPU/CuPy gracefully fall back to optimized CPU execution.
- **Benchmark**: Included `examples/gpu_benchmark.py` to verify speedups.

### 5. üõ†Ô∏è Code Quality (v4.1 Final)
- **Zero TODO Comments**: All placeholder implementations have been completed.
- **Parameter Bounds**: ES Optimizer now clamps parameters to prevent divergence.
- **Abstract Method Compliance**: All layers now properly implement required abstract methods.
- **Layer Stability**: Fixed namespace collision in `TemporalLayer` between activation attribute and method.

## üõ†Ô∏è Full Changelog

- **Added**: `pyproject.toml`, `MANIFEST.in`, `setup.py` for PyPI distribution readiness.
- **Added**: `benchmark.py` for performance validation.
- **Added**: Configuration templates with parameter descriptions.
- **Improved**: `STDPRule` logic to include nonlinear interaction terms.
- **Improved**: `MetaOptimizer.outer_update` now uses adaptive parameter perturbation.
- **Improved**: `MetaOptimizer._sample_task` now supports curriculum and performance-weighted sampling.
- **Fixed**: `HierarchyManager.remove_level` documentation and cleanliness.
- **Fixed**: `ReactiveLayer.activation()` method implementation.
- **Fixed**: `TemporalLayer` activation attribute/method namespace collision.
- **Fixed**: Indentation issues in `validate_config`.
- **Moved**: `orthos_v3_1.py` prototype to `examples/` to maintain clean root.

## üîú Next Steps: v4.2
See [Sparse Attention Specification](docs/architecture/features/sparse_attention.md) for the detailed v4.2 architecture plan.

---
*Ready to deploy. Happy hacking!* üß†
